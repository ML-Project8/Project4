{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Four: Extending Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Austin Chen, Luke Hansen, Oscar Vallner*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation and Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In today's world, it might be easy to make the assumption that those who have higher paying jobs must have achieved a higher level of education at some point in their lifetimes. For example, one might expect an employee who achieved a Masters degree to get paid more than an employee who only achieved a high school diploma. For the last couple decades, it has been a topic of wide cultural debate, whether higher level degrees of education (Masters and Doctoral) are worthy investments in careers.\n",
    "\n",
    "Therefore, we have chosen to analyze a subset of 40 year's worth of the United States' federal payroll records. This large dataset contains the payroll records of government employees for the past 40 years. Our federal payroll data was obtained through the Freedom of Information Act by BuzzFeed news. We have chosen government payroll data for a few different reasons. First, having such a large volume of data (40 years worth of payroll records) provides us with flexibility; with a large dataset, we have the ability to subsample--whether it be randomized, by department, or year. Second, as patrons and benefactors of the United States Government, we have chosen to place faith in the assumption that officially published government data is accurate. The dataset contains several attributes regarding education level, payment, government agency division, etc. with each specific employees name abstracted. By trusting the integrity of this data, we can potentially create a useful, real-world classifier to predict an employee's highest education level. Even if the government has lied about the accuracy of the data, rendering the classifier useless for their internal operations, the classifier can still be useful to the public, contingent on an high accuracy rate.\n",
    "\n",
    "\n",
    "While there is no singular use-case that this data is meant to solve, we have decided to pick apart this payroll data in order to see if there are any meaningful conclusions we can draw on any government worker's career and life decisions, based on data of their current job position. Perhaps it is _indeed_ true that those who achieve higher levels of education end up with higher compensations. It could be the case, however, that higher government compensation is merely a function of a longer length of service. We hope that through building a classifier, we can answer some of these questions.\n",
    "\n",
    "Due to the sheer volume of the dataset, we have decided to take a subset of the 40 years of data, and narrow our focus to an easy-to-grasp classification problem regarding educational level. Given attributes such as the agency division, age, length of service, pay, and more, we will be attempting to clasisfy the highest level of education each employee received.\n",
    "\n",
    "There may not be any __short-term__, immediate actions one could take with these results. However, through time, a trained Logistic Regression classifier could aid the United States government in analyzing the value of educational degrees in government jobs. By looking at factors such as pay, length of service, and age, the United States government could more appropriately create compensation models for their employees based off their highest level of education. Or, they could use any conclusions drawn from the classifer to verify whether the compensation consistency between many employees with the same degree. Furthermore, a classification model that is able to accurately predict an employee's education level could potentially be extended to contexts beyond government jobs. With enough data exploration, a classification model such as ours could be experimented with in other paradigms of the career market. _Perhaps_ a Masters degree isn't reflective of higher salaries in a government job, but could be indicative of higher compensation in a discipline such as engineering, business, or education. \n",
    "\n",
    "We ultimately decided to divide our classification problem into four classes. Each class represents the HIGHEST edcuation level that an employee attained.\n",
    "\n",
    "1. Highschool (or under) not completed\n",
    "2. Highschool Completed\n",
    "3. Bachelor's Completed\n",
    "4. Graduate degree completed (Masters and up)\n",
    "\n",
    "As a baseline, our classification model should at least beat random, 25%. However, because this classification model could directly affect the United States government and its decisions, we should plan for our model to be as accurate as possible. In order to make helpful, informed decisions for the United States government based on our classification model, we wish to obtain at least 85% accuracy.\n",
    "\n",
    "\n",
    "---\n",
    "Link to dataset: https://ia600608.us.archive.org/16/items/opm-federal-employment-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Class Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning:\n",
      "\n",
      "Columns (9,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "2    306080\n",
      "3    216420\n",
      "4    137024\n",
      "1      8342\n",
      "Name: Education, dtype: int64\n",
      "------------------\n",
      "0    578320\n",
      "1     89546\n",
      "Name: SupervisoryStatus, dtype: int64\n",
      "------------------\n",
      "Total:  667866\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('data/2014-clean.csv', encoding = 'latin1')\n",
    "df_adjust = df\n",
    "\n",
    "# Encodes education into a much more manageable prediction attribute\n",
    "df_adjust.Education[df_adjust.Education < 4] = 1\n",
    "df_adjust.Education[(df_adjust.Education > 3) & (df_adjust.Education < 13)] = 2\n",
    "df_adjust.Education[(df_adjust.Education > 12) & (df_adjust.Education < 17)] = 3\n",
    "df_adjust.Education[df_adjust.Education > 16] = 4\n",
    "\n",
    "#Binary encode, 8 is not supervisor, <8 are unordered types of supervisors\n",
    "df_adjust.SupervisoryStatus[df_adjust.SupervisoryStatus < 8] = 1\n",
    "df_adjust.SupervisoryStatus[df_adjust.SupervisoryStatus == 8] = 0\n",
    "\n",
    "#ensure data is integer encoded\n",
    "df_adjust = df_adjust[np.isfinite(df_adjust['Education'])]\n",
    "df_adjust = df_adjust[np.isfinite(df_adjust['SupervisoryStatus'])]\n",
    "df_adjust.Education = df_adjust.Education.astype(int)\n",
    "df_adjust.SupervisoryStatus = df_adjust.SupervisoryStatus.astype(int)\n",
    "\n",
    "# Encodes Length of Service\n",
    "df_adjust.LOS[df_adjust.LOS == '< 1'] = 0\n",
    "df_adjust.LOS[df_adjust.LOS == '1-2'] = 1\n",
    "df_adjust.LOS[df_adjust.LOS == '3-4'] = 2\n",
    "df_adjust.LOS[df_adjust.LOS == '5-9'] = 3\n",
    "df_adjust.LOS[df_adjust.LOS == '10-14'] = 4\n",
    "df_adjust.LOS[df_adjust.LOS == '15-19'] = 5\n",
    "df_adjust.LOS[df_adjust.LOS == '20-24'] = 6\n",
    "df_adjust.LOS[df_adjust.LOS == '25-29'] = 7\n",
    "df_adjust.LOS[df_adjust.LOS == '30-34'] = 8\n",
    "df_adjust.LOS[df_adjust.LOS == '35+'] = 9\n",
    "df_adjust.LOS[df_adjust.LOS == 'UNSP'] = np.NaN\n",
    "\n",
    "df_adjust = df_adjust.dropna()\n",
    "\n",
    "#convert to integer\n",
    "df_adjust.Pay = df_adjust.Pay.astype(int)\n",
    "df_adjust.LOS = df_adjust.LOS.astype(int)\n",
    "\n",
    "print(type(df))\n",
    "\n",
    "print(df_adjust.Education.value_counts())\n",
    "print(\"------------------\")\n",
    "print(df_adjust.SupervisoryStatus.value_counts())\n",
    "print(\"------------------\")\n",
    "print(\"Total: \", len(df_adjust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df_adjust.Education.value_counts())\n",
    "print(len(df_adjust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_adjust[['PseudoID', 'Name', 'Date', 'Agency','Station','Age','Education','PayPlan','Grade', 'LOS', 'Occupation', 'Category','Pay', 'SupervisoryStatus','Appointment', 'Schedule', 'NSFTP', 'AgencyName']].head()\n",
    "removed_cols = df_adjust[['Agency','Age','Education','PayPlan', 'LOS', 'Category','Pay', 'SupervisoryStatus', 'Schedule', 'NSFTP', 'AgencyName']]\n",
    "print(removed_cols.head())\n",
    "print(removed_cols.describe())\n",
    "for x in removed_cols:\n",
    "    print(x, \" : \", len(removed_cols[x].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one hot encode necessary data\n",
    "dummies = pd.get_dummies(data=removed_cols, columns=['Agency', 'Age', 'PayPlan', 'Category', 'SupervisoryStatus', 'Schedule', 'NSFTP', 'AgencyName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train-Test-Split & Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOS</th>\n",
       "      <th>Pay</th>\n",
       "      <th>Agency_DJ01</th>\n",
       "      <th>Agency_DJ02</th>\n",
       "      <th>Agency_DJ03</th>\n",
       "      <th>Agency_DJ06</th>\n",
       "      <th>Agency_DJ07</th>\n",
       "      <th>Agency_DJ08</th>\n",
       "      <th>Agency_DJ09</th>\n",
       "      <th>Agency_DJ10</th>\n",
       "      <th>...</th>\n",
       "      <th>AgencyName_SURFACE TRANSPORTATION BOARD</th>\n",
       "      <th>AgencyName_TRANSPORTATION SECURITY ADMINISTRATION</th>\n",
       "      <th>AgencyName_U.S. COAST GUARD</th>\n",
       "      <th>AgencyName_U.S. FISH AND WILDLIFE SERVICE</th>\n",
       "      <th>AgencyName_U.S. MARSHALS SERVICE</th>\n",
       "      <th>AgencyName_U.S. SECRET SERVICE</th>\n",
       "      <th>AgencyName_U.S. TRUSTEE PROGRAM</th>\n",
       "      <th>AgencyName_VETERAN EMPLOYMENT SERVICES OFFICE</th>\n",
       "      <th>AgencyName_VETERANS BENEFITS ADMINISTRATION</th>\n",
       "      <th>AgencyName_VETERANS HEALTH ADMINISTRATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>485504</th>\n",
       "      <td>4</td>\n",
       "      <td>69276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358345</th>\n",
       "      <td>5</td>\n",
       "      <td>87731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891253</th>\n",
       "      <td>1</td>\n",
       "      <td>42823</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386719</th>\n",
       "      <td>3</td>\n",
       "      <td>76446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593279</th>\n",
       "      <td>7</td>\n",
       "      <td>44745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 466 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LOS    Pay  Agency_DJ01  Agency_DJ02  Agency_DJ03  Agency_DJ06  \\\n",
       "485504   4  69276            0            0            0            0   \n",
       "358345   5  87731            0            0            0            0   \n",
       "891253   1  42823            0            0            0            0   \n",
       "386719   3  76446            0            0            0            0   \n",
       "593279   7  44745            0            0            0            0   \n",
       "\n",
       "        Agency_DJ07  Agency_DJ08  Agency_DJ09  Agency_DJ10  \\\n",
       "485504            0            0            0            0   \n",
       "358345            0            0            0            0   \n",
       "891253            0            0            0            0   \n",
       "386719            0            0            0            0   \n",
       "593279            0            0            0            0   \n",
       "\n",
       "                          ...                      \\\n",
       "485504                    ...                       \n",
       "358345                    ...                       \n",
       "891253                    ...                       \n",
       "386719                    ...                       \n",
       "593279                    ...                       \n",
       "\n",
       "        AgencyName_SURFACE TRANSPORTATION BOARD  \\\n",
       "485504                                        0   \n",
       "358345                                        0   \n",
       "891253                                        0   \n",
       "386719                                        0   \n",
       "593279                                        0   \n",
       "\n",
       "        AgencyName_TRANSPORTATION SECURITY ADMINISTRATION  \\\n",
       "485504                                                  0   \n",
       "358345                                                  0   \n",
       "891253                                                  0   \n",
       "386719                                                  0   \n",
       "593279                                                  0   \n",
       "\n",
       "        AgencyName_U.S. COAST GUARD  \\\n",
       "485504                            0   \n",
       "358345                            0   \n",
       "891253                            0   \n",
       "386719                            0   \n",
       "593279                            0   \n",
       "\n",
       "        AgencyName_U.S. FISH AND WILDLIFE SERVICE  \\\n",
       "485504                                          0   \n",
       "358345                                          0   \n",
       "891253                                          0   \n",
       "386719                                          0   \n",
       "593279                                          0   \n",
       "\n",
       "        AgencyName_U.S. MARSHALS SERVICE  AgencyName_U.S. SECRET SERVICE  \\\n",
       "485504                                 0                               0   \n",
       "358345                                 0                               0   \n",
       "891253                                 0                               0   \n",
       "386719                                 0                               0   \n",
       "593279                                 0                               0   \n",
       "\n",
       "        AgencyName_U.S. TRUSTEE PROGRAM  \\\n",
       "485504                                0   \n",
       "358345                                0   \n",
       "891253                                0   \n",
       "386719                                0   \n",
       "593279                                0   \n",
       "\n",
       "        AgencyName_VETERAN EMPLOYMENT SERVICES OFFICE  \\\n",
       "485504                                              0   \n",
       "358345                                              0   \n",
       "891253                                              0   \n",
       "386719                                              0   \n",
       "593279                                              0   \n",
       "\n",
       "        AgencyName_VETERANS BENEFITS ADMINISTRATION  \\\n",
       "485504                                            0   \n",
       "358345                                            0   \n",
       "891253                                            0   \n",
       "386719                                            0   \n",
       "593279                                            0   \n",
       "\n",
       "        AgencyName_VETERANS HEALTH ADMINISTRATION  \n",
       "485504                                          0  \n",
       "358345                                          0  \n",
       "891253                                          1  \n",
       "386719                                          0  \n",
       "593279                                          0  \n",
       "\n",
       "[5 rows x 466 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(dummies.drop('Education',1), dummies.Education, test_size=0.20, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "    \n",
    "    # convenience, private:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    \n",
    "        \n",
    "blr = BinaryLogisticRegressionBase(0.1)\n",
    "print(blr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 One-versus-all Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Performance Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Comparing Results to sci-kit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Integrating with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inherit from base class\n",
    "class BinaryLogisticRegression(BinaryLogisticRegressionBase):\n",
    "    #private:\n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    def _get_gradient(self,X,y):\n",
    "        # programming \\sum_i (yi-g(xi))xi\n",
    "        gradient = np.zeros(self.w_.shape) # set gradient to zero\n",
    "        for (xi,yi) in zip(X,y):\n",
    "            # the actual update inside of sum\n",
    "            gradi = (yi - self.predict_proba(xi,add_bias=False))*xi \n",
    "            # reshape to be column vector and add to gradient\n",
    "            gradient += gradi.reshape(self.w_.shape) \n",
    "        \n",
    "        return gradient/float(len(y))\n",
    "       \n",
    "    # public:\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n",
    "\n",
    "            \n",
    "blr = BinaryLogisticRegression(0.1)\n",
    "print(blr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_adjust.Pay\n",
    "y = df_adjust.Education # make problem binary\n",
    "\n",
    "plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "\n",
    "graph1 = {'labels': np.unique(y),\n",
    "          'values': np.bincount(y),\n",
    "            'type': 'pie'}\n",
    "fig = dict()\n",
    "fig['data'] = [graph1]\n",
    "fig['layout'] = {'title': 'Binary Class Distribution',\n",
    "                'autosize':False,\n",
    "                'width':500,\n",
    "                'height':300}\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat = blr.predict(X)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# can we do better? Maybe more iterations?\n",
    "params = dict(eta=0.1,\n",
    "              iterations=500)\n",
    "\n",
    "blr = BinaryLogisticRegression(**params)\n",
    "blr.fit(X,y)\n",
    "print(blr)\n",
    "yhat = blr.predict(X)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# now lets do some vectorized coding\n",
    "from scipy.special import expit\n",
    "\n",
    "class VectorBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # but overwrite the gradient calculation\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        return gradient.reshape(self.w_.shape)\n",
    "\n",
    "# use same params as defined above\n",
    "blr = VectorBinaryLogisticRegression(**params)\n",
    "blr.fit(X,y)\n",
    "print(blr.w_)\n",
    "yhat = blr.predict(X)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = y==yval # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = VectorBinaryLogisticRegression(self.eta,self.iters)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row\n",
    "    \n",
    "lr = LogisticRegression(0.1,1500)\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = load_iris()\n",
    "X = ds.data\n",
    "y = ds.target # note problem is NOT binary anymore, there are three classes!\n",
    "\n",
    "print(type(ds.data))\n",
    "print(ds.data)\n",
    "print(ds.target)\n",
    "\n",
    "lr = LogisticRegression(0.1,500)\n",
    "\n",
    "lr.fit(X,y)\n",
    "print(lr)\n",
    "\n",
    "yhat = lr.predict(X)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
